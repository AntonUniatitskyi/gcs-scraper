import chromadb
from sentence_transformers import SentenceTransformer
import os
import uuid
from loguru import logger

class MemoryHandler:
    def __init__(self, db_path="chroma_db"):
        self.client = chromadb.PersistentClient(path=db_path)
        self.collection = self.client.get_or_create_collection(name="news_knowledge")
        self.model = SentenceTransformer('all-MiniLM-L6-v2')

    def add_article(self, article_data):
        if not article_data.get('text_content') or len(article_data['text_content']) < 100:
            return

        url = article_data.get('url')
        text = article_data.get('text_content')[:1000] # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ ÐºÑƒÑÐ¾Ðº Ð´Ð»Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸
        title = article_data.get('title') or "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ"
        date = article_data.get('published_date') or "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"
        vector = self.model.encode(text).tolist()

        try:
            self.collection.upsert(
                documents=[text],
                embeddings=[vector],
                metadatas=[{"url": url, "title": title, "date": str(date)}],
                ids=[url] # URL ÐºÐ°Ðº ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ID
            )
            logger.debug(f"ðŸ’¾ Ð—Ð°Ð¿Ð¾Ð¼Ð½Ð¸Ð» ÑÑ‚Ð°Ñ‚ÑŒÑŽ: {title}")
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ð¼ÑÑ‚Ð¸: {e}")

    def find_similar_context(self, query_text, n_results=3):
        if not query_text: return ""
        vector = self.model.encode(query_text).tolist()
        results = self.collection.query(
            query_embeddings=[vector],
            n_results=n_results
        )

        context_str = ""
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                meta = results['metadatas'][0][i]
                context_str += f"\n[ÐÑ€Ñ…Ð¸Ð²: {meta['date']} | {meta['title']}]\n{doc[:300]}...\n"

        return context_str
