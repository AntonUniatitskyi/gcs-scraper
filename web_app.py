import streamlit as st
import asyncio
import pandas as pd
import page_parser as parser
from search_client import SearchClient
from config import API_KEY, SEARCH_ENGINE_ID
from database import DatabaseHandler
import plotly.express as px
from report_generator import create_pdf

def color_rating(val):
    if not isinstance(val, str): return ''
    if '–í—ã—Å–æ–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ' in val:
        return 'background-color: #d4edda; color: #155724'  # Green
    elif '–ü—Ä–æ–ø–∞–≥–∞–Ω–¥–∞' in val or '–ù–∏–∑–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ' in val:
        return 'background-color: #f8d7da; color: #721c24'  # Red
    elif '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞' in val:
        return 'background-color: #fff3cd; color: #856404'  # Yellow
    return ''

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ù–æ–≤–æ—Å—Ç–µ–π", page_icon="üõ°Ô∏è", layout="wide")
st.title("üõ°Ô∏è AI-–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ù–æ–≤–æ—Å—Ç–µ–π –∏ –ü—Ä–æ–ø–∞–≥–∞–Ω–¥—ã")

db = DatabaseHandler()

async def run_analysis(query, num_results):
    st.session_state.is_running = True
    st.session_state.report_data = None

    status_placeholder = st.empty()
    status_placeholder.info(f"üîé –ò—â—É {num_results} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è: **{query}**...")

    try:
        client = SearchClient(API_KEY, SEARCH_ENGINE_ID)
        results_data = client.search(query, num_results, show_logs=False)
    except ValueError as e:
        status_placeholder.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        st.session_state.is_running = False
        return

    if not results_data or not results_data.get('items'):
        status_placeholder.warning("‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        st.session_state.is_running = False
        return

    links_count = len(results_data['items'])
    status_placeholder.info(f"üîó –ù–∞–π–¥–µ–Ω–æ {links_count} —Å—Å—ã–ª–æ–∫. –ó–∞–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ AI –∏ –ø–∞—Ä—Å–∏–Ω–≥...")

    final_report_data = await parser.run_parser(results_data, query, show_logs=False)

    st.session_state.report_data = final_report_data
    status_placeholder.success(f"‚úÖ –ê–Ω–∞–ª–∏–∑ {links_count} —Å—Ç–∞—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω!")
    st.session_state.is_running = False

if 'is_running' not in st.session_state:
    st.session_state.is_running = False
if 'report_data' not in st.session_state:
    st.session_state.report_data = None

with st.sidebar:
    st.header("üîç –ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
    search_query = st.text_input("–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å", key="search_query")
    num_results = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", 1, 10, 5)
    if st.button("üöÄ –ù–∞—á–∞—Ç—å –ê–Ω–∞–ª–∏–∑", disabled=st.session_state.is_running, type="primary"):
        if search_query:
            try:
                asyncio.run(run_analysis(search_query, num_results))
            except RuntimeError as e:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(run_analysis(search_query, num_results))
                loop.close()

    st.markdown("---")
    st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–∞–∑—ã")
    stats = db.get_stats()
    col1, col2 = st.columns(2)
    col1.metric("–í—Å–µ–≥–æ", stats['total'])
    col2.metric("–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ", stats['trusted'])
    st.metric("–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ / –ü—Ä–æ–ø–∞–≥–∞–Ω–¥–∞", stats['fake'], delta_color="inverse")

if st.session_state.report_data:
    st.divider()
    st.subheader("üìç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–∏—Å–∫–∞")

    df_report = pd.DataFrame(st.session_state.report_data)
    st.dataframe(
        df_report.style.map(color_rating, subset=['rating']),
        use_container_width=True,
        column_config={
            "url": st.column_config.LinkColumn("URL", display_text="–û—Ç–∫—Ä—ã—Ç—å —Å—Å—ã–ª–∫—É"),
            "ai_analysis": st.column_config.TextColumn("AI –ê–Ω–∞–ª–∏–∑", width="large")
        }
    )

    st.markdown("#### ‚öîÔ∏è –°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (Cross-Check)")

    with st.expander("‚ÑπÔ∏è –ß—Ç–æ —ç—Ç–æ?", expanded=False):
        st.info("AI —Å—Ä–∞–≤–Ω–∏—Ç —Ç–µ–∫—Å—Ç—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π, –Ω–∞–π–¥–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ —Ñ–∞–∫—Ç–∞—Ö –∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏.")

    if st.button("‚ú® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç"):
        current_data = st.session_state.get('report_data')

        if not current_data:
             st.error("–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö.")
        else:
            has_text = any(item.get('text_content') for item in current_data)
            if not has_text:
                st.error("‚ö†Ô∏è –ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –í–æ–∑–º–æ–∂–Ω–æ, —Å–∞–π—Ç—ã –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–∏ –ø–∞—Ä—Å–µ—Ä.")
            else:
                cross_check_result = ""
                with st.spinner("ü§ñ AI —á–∏—Ç–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ –∏ –∏—â–µ—Ç –∏—Å—Ç–∏–Ω—É..."):
                    try:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        cross_check_result = loop.run_until_complete(
                            parser.get_cross_check_analysis(current_data)
                        )
                        loop.close()

                        st.success("–ì–æ—Ç–æ–≤–æ!")
                        with st.container(border=True):
                            st.markdown(cross_check_result)

                            # pdf_data = create_pdf(
                            #     query=search_query,
                            #     articles=current_data,
                            #     cross_check_text=cross_check_result
                            # )

                            # st.download_button(
                            #     label="üìÑ –°–∫–∞—á–∞—Ç—å PDF –æ—Ç—á–µ—Ç",
                            #     data=pdf_data,
                            #     file_name="analysis_report.pdf",
                            #     mime="application/pdf",
                            #     type="primary"
                            # )
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –∫—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑–∞: {e}")
                if cross_check_result:
                    try:
                        with st.spinner("üìÑ –í–µ—Ä—Å—Ç–∞—é PDF –æ—Ç—á–µ—Ç..."):
                            pdf_data = create_pdf(
                                query=search_query,
                                articles=current_data,
                                cross_check_text=cross_check_result
                            )

                        st.download_button(
                            label="üìÑ –°–∫–∞—á–∞—Ç—å PDF –æ—Ç—á–µ—Ç",
                            data=pdf_data,
                            file_name="analysis_report.pdf",
                            mime="application/pdf",
                            type="primary"
                        )
                    except IndexError:
                        st.error("‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PDF (IndexError).")
                        # st.warning("–°–æ–≤–µ—Ç: –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –ø—Ä–æ–±–ª–µ–º–∞ –≤ report_generator.py –ø—Ä–∏ —Ä–∞–∑–±–∏–≤–∫–µ —Ç–µ–∫—Å—Ç–∞.")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF: {e}")
st.divider()
st.subheader("üìö –ò—Å—Ç–æ—Ä–∏—è –∏ –¢—Ä–µ–Ω–¥—ã (–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö)")

df_history = db.get_all_articles_df()

if not df_history.empty:
    df_history['clean_rating'] = df_history['rating'].astype(str).apply(
        lambda x: x.split('|')[0].replace('–†–µ–π—Ç–∏–Ω–≥:', '').split('(')[0].strip()
    )

    df_history['published_date'] = df_history['published_date'].astype(str)
    df_history['published_date_dt'] = pd.to_datetime(df_history['published_date'], errors='coerce', utc=True)
    df_history['date_parsed'] = df_history['published_date_dt'].dt.date

    tab1, tab2 = st.tabs(["üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", "üìã –¢–∞–±–ª–∏—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏"])

    with tab1:
        col1, col2 = st.columns(2)

        with col1:
            rating_counts = df_history['clean_rating'].value_counts().reset_index()
            rating_counts.columns = ['–ò—Å—Ç–æ—á–Ω–∏–∫', '–ö–æ–ª-–≤–æ']
            fig_pie = px.pie(
                rating_counts, values='–ö–æ–ª-–≤–æ', names='–ò—Å—Ç–æ—á–Ω–∏–∫',
                title='–î–æ–≤–µ—Ä–∏–µ –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º', hole=0.4,
                color='–ò—Å—Ç–æ—á–Ω–∏–∫',
                color_discrete_map={
                    '–í—ã—Å–æ–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ': '#28a745',
                    '–ù–∏–∑–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ / –ü—Ä–æ–ø–∞–≥–∞–Ω–¥–∞': '#dc3545',
                    '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞': '#ffc107',
                    '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω': '#6c757d'
                }
            )
            st.plotly_chart(fig_pie, use_container_width=True)

        with col2:
            valid_dates = df_history.dropna(subset=['date_parsed'])
            if not valid_dates.empty:
                date_counts = valid_dates['date_parsed'].value_counts().reset_index()
                date_counts.columns = ['–î–∞—Ç–∞', '–°—Ç–∞—Ç–µ–π']
                date_counts = date_counts.sort_values('–î–∞—Ç–∞')
                fig_bar = px.bar(
                    date_counts, x='–î–∞—Ç–∞', y='–°—Ç–∞—Ç–µ–π',
                    title='–•—Ä–æ–Ω–æ–ª–æ–≥–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π',
                    color_discrete_sequence=['#3498db']
                )
                st.plotly_chart(fig_bar, use_container_width=True)
            else:
                st.info("–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö —Å –¥–∞—Ç–∞–º–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞.")

    with tab2:
        st.dataframe(
            df_history.style.map(color_rating, subset=['rating']),
            use_container_width=True,
            column_config={
                "url": st.column_config.LinkColumn("URL", display_text="üîó"),
                "ai_analysis": st.column_config.TextColumn("AI –ê–Ω–∞–ª–∏–∑", width="large"),
                "retrieved_at": st.column_config.DatetimeColumn("–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ", format="DD.MM.YYYY HH:mm")
            }
        )
else:
    st.info("–ò—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ–∫–∞ –ø—É—Å—Ç–∞.")
